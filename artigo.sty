\documentclass[11pt]{article}

% Final version for ACL format
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% UTF-8
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% Improvements
\usepackage{microtype}
\usepackage{inconsolata}

% Images
\usepackage{graphicx}

% Title
\title{Integração de Detecção de Subjetividade e Extração de Causas de Emoção: \\
Um Pipeline Híbrido com Modelos Transformer}

\author{
  Thiago Augusto \\
  \texttt{thiago@example.com}
  \And
  Thayanne Viegas \\
  \texttt{thayanne@example.com}
}

\begin{document}
\maketitle

\begin{abstract}
Este trabalho investiga a relação entre subjetividade textual e a extração de causas de emoções, propondo um pipeline híbrido que integra duas tarefas tradicionalmente tratadas de forma independente no PLN. Na primeira etapa, um modelo Transformer é fine-tuned na Task 1 do CheckThat! 2025 para identificar trechos subjetivos em notícias. Em seguida, apenas esses segmentos são encaminhados para um modelo de Question Answering treinado na Task 3 do SemEval-2024, responsável por extrair spans que representam causas emocionais. Avaliamos duas hipóteses: (i) trechos subjetivos tendem a apresentar emoções ou elementos que facilitam a identificação de suas causas, o que foi empiricamente confirmado; e (ii) a filtragem por subjetividade melhora sistematicamente o desempenho da extração de causas, hipótese que não se sustentou. Os resultados mostram que, embora subjetividade esteja correlacionada à presença de conteúdo emocional, ela não é suficiente para otimizar o processo de ECE, sugerindo que fatores discursivos mais amplos influenciam a identificação causal. O estudo contribui ao propor a primeira integração explícita entre detecção de subjetividade e extração de causas emocionais, avaliando empiricamente sua viabilidade e limitações, e apontando caminhos metodológicos e éticos para avanços futuros.
\end{abstract}

\section{Introdução}

A identificação automática de fenômenos pragmáticos e subjetivos em texto tem se tornado um tópico central em Processamento de Linguagem Natural (PLN). Entre essas tarefas, destacam-se a detecção de subjetividade, responsável por distinguir sentenças objetivas de subjetivas, e a análise de causas de emoções, que consiste em localizar trechos textuais que explicam a origem de uma emoção expressa. Apesar de serem tratadas majoritariamente de forma independente na literatura, essas tarefas apresentam forte interdependência linguística: a subjetividade costuma emergir em contextos onde estados internos, opiniões ou emoções são expressos.

Neste trabalho propomos um pipeline em duas etapas: (1) um modelo Transformer fine-tuned na Task 1 do CheckThat! 2025, responsável por detectar trechos subjetivos em notícias; e (2) um modelo de Question Answering (QA) treinado na Task 3 do SemEval 2024, utilizado para extrair as causas das emoções em trechos pré-selecionados pelo primeiro modelo. Nossa hipótese é que a filtragem prévia de subjetividade melhora a precisão do modelo de extração de causas ao reduzir ruído contextual e direcionar o QA para trechos mais propensos a carregar causas explícitas.

Este estudo traz três contribuições principais:

Integração inédita de duas tarefas de competições diferentes: subjetividade (CheckThat!) e causa de emoção (SemEval).

Proposta de pipeline pragmático, onde a saída da detecção de subjetividade condiciona a entrada do modelo QEAC (Emotion Cause Extraction).

Avaliação empírica da hipótese linguística de que subjetividade antecede e facilita a identificação de causas emocionais.

\section{Trabalhos Relacionados}

A detecção de subjetividade e a extração de causas de emoções têm sido estudadas de forma independente na literatura de PLN, embora ambas sejam tarefas centrais na compreensão pragmático-discursiva do texto. Nesta seção, revisamos trabalhos fundamentais nessas duas áreas, além de iniciativas mais recentes que exploram multitarefas relacionadas à emoção e subjetividade.

\subsection{Detecção de Subjetividade}

Os estudos iniciais de subjetividade no PLN foram conduzidos por \citet{wiebe2005annotating}, cujo trabalho seminal definiu a tarefa de identificar segmentos subjetivos em texto. Abordagens tradicionais baseavam-se em léxicos e regras linguísticas, mas com o avanço de modelos pré-treinados como BERT e RoBERTa, tornou-se padrão o uso de Transformers para essa tarefa.

Trabalhos contemporâneos, como o survey de \citet{qiu2022survey}, mostram que modelos Transformer dominam benchmarks de subjetividade, alcançando F1 superior a 90\% em corpora balanceados. Além disso, investigações recentes combinam subjetividade com outras tarefas afetivas via aprendizado multitarefa, como em \citet{arias2022subjectivityMTL}, que demonstram que prever subjetividade ajuda modelos de polaridade a convergirem melhor.

Nas campanhas do CheckThat! (CLEF), subjetividade aparece como tarefa auxiliar na triagem de enunciados potencialmente verificáveis. Competições de 2022 a 2024 mostram o domínio de modelos pré-treinados, como relatado em \citet{checkthat2024overview}, consolidando Transformers como arquitetura padrão para a detecção automática de subjetividade em notícias.

\subsection{Extração de Causas de Emoção}

A tarefa de Emotion Cause Extraction (ECE) foi inicialmente estruturada como problema linguístico por \citet{neviarouskaya2013extracting}. Posteriormente, \citet{gui2017question} transformaram a tarefa ao propor um modelo baseado em Question Answering (QA), no qual a causa é tratada como um span a ser extraído do texto, alcançando avanços substanciais em desempenho.

Modelos hierárquicos como a RTHN (\citealp{tay2019rthn}) propõem arquiteturas híbridas com RNNs e Transformers para capturar relações entre cláusulas, melhorando a identificação de causas emocionais em narrativas longas. Já \citet{yan2021positionbias} evidenciam o impacto de vieses de posição presentes em corpora de ECE e propõem grafos de conhecimento para mitigar esse problema.

Outra vertente importante é o Emotion–Cause Pair Extraction (ECPE), introduzido por \citet{xia2019ecpe}, que elimina a necessidade de emoção anotada a priori e busca extrair simultaneamente emoções e suas causas.

\subsection{ECE em Conversações}

A extração de causas emocionais em diálogos surge como subcampo recente, com o dataset RECCON introduzido por \citet{poria2021reccon}. Esse corpus define subtarefas de span extraction e causal entailment. Trabalhos como \citet{bhat2022mutec} utilizam aprendizado multitarefa para prever emoção, causa e relação causal simultaneamente.

Em paralelo, \citet{nguyen2023guidedqa} tratam ECPE como QA, utilizando uma primeira pergunta para identificar a emoção e uma segunda para localizar a causa correspondente. Abordagens baseadas em atenção contextual, como a DQAN apresentada por \citet{sun2021dqan}, melhoram a representação conjunta de emoção e causa.

\subsection{Integração entre Subjetividade e Causas de Emoção}

Apesar da forte relação linguística entre subjetividade e emoções, a literatura ainda carece de modelos que integrem explicitamente ambas as tarefas. Trabalhos de multitarefa exploram polaridade, sentimento e subjetividade \citep{arias2022subjectivityMTL}, mas não há, até onde pudemos verificar, abordagens que utilizem a detecção prévia de subjetividade para melhorar a extração de causas emocionais.

O pipeline proposto neste trabalho preenche essa lacuna ao introduzir a detecção de subjetividade como filtro pragmático antes da etapa de QA para extração de causas, estabelecendo uma conexão metodológica inédita entre duas linhas de pesquisa historicamente tratadas de forma independente.

\section{Hipóteses de Pesquisa}

\subsection{Hipótese 1: Textos subjetivos apresentam emoções associadas}

A primeira hipótese postulava que trechos subjetivos tenderiam a conter, de forma explícita ou implícita, expressões emocionais ou estruturas linguísticas indicativas de estados afetivos. Essa hipótese deriva da literatura em pragmática e análise de opinião, segundo a qual subjetividade costuma emergir justamente em contextos onde o falante expressa avaliações, julgamentos ou emoções.

Os resultados experimentais confirmaram essa hipótese. A etapa de detecção de subjetividade — apoiada no modelo Transformer fine-tuned para a Task 1 do CheckThat! 2025 — mostrou que sentenças classificadas como subjetivas são, de fato, aquelas nas quais o modelo de extração de causas emocionais (Task 3 do SemEval-2024) encontra com maior frequência causas válidas e spans emocionalmente relevantes. Na integração entre as duas tarefas, verificou-se que a filtragem por subjetividade reduz ruído contextual e aumenta a probabilidade de o modelo de QA identificar corretamente causas emocionais, reforçando a premissa linguística inicial.

\subsection{Hipótese 2: A filtragem por subjetividade melhora sistematicamente o desempenho do modelo de ECE}

A segunda hipótese assumia que, ao restringir o conjunto de entradas para o modelo de QA apenas a sentenças subjetivas, haveria melhora consistente e sistemática no desempenho da extração de causas de emoção. Em outras palavras, esperava-se que o pipeline híbrido superasse o modelo de QA aplicado diretamente ao texto completo, independentemente da variabilidade dos diálogos e do tipo de emoção.

Contudo, essa hipótese não se confirmou. Embora a filtragem por subjetividade tenha reduzido o espaço de busca e introduzido uma etapa pragmática útil, não foi observada melhora sistemática nos resultados do QA. Em alguns cenários, a filtragem chegou a suprimir contextos relevantes para a determinação da causa emocional; em outros, manteve trechos subjetivos que não necessariamente continham informação causal. Assim, a hipótese se demonstrou falsa, indicando que a subjetividade, apesar de correlacionada à presença de emoção, não é um critério suficiente para otimizar a extração de causas no formato QA.

Esses achados sugerem que a relação entre subjetividade e causalidade emocional é mais complexa do que a hipótese inicial pressupunha. Embora subjetividade seja um bom indicador da presença de conteúdo emocional, a localização da causa depende de fatores discursivos mais amplos, incluindo coesão global do diálogo, dependências entre turnos e variações estilísticas que não são capturadas unicamente pela classificação subjetivo/objetivo.



\section{Método}

Nesta seção detalhamos o desenvolvimento das duas tarefas propostas: (i) detecção de subjetividade em notícias, baseada no corpus da CheckThat! Lab (CLEF 2025), e (ii) identificação de causa de emoção em diálogos, conforme o desafio SemEval-2024 Emotional Causality in Conversations (ECAC). Cada pipeline foi construído, treinado e avaliado separadamente, respeitando a natureza das tarefas e utilizando modelos baseados em Transformers.

\subsection{Task 1 – Detecção de Subjetividade em Notícias (CheckThat! 2025)}

A primeira parte do experimento consiste em detectar se um trecho noticioso é subjetivo ou objetivo, uma tarefa de classificação binária. Os dados foram obtidos diretamente do repositório oficial do CheckThat! Lab, contendo subdivisões para train, validation, dev\_test, test\_labeled e test\_unlabeled. Cada instância é composta por um campo textual (sentence) e por um rótulo categórico (OBJ ou SUBJ).

\subsubsection{Preparação dos dados}

Inicialmente, o conjunto de dados é carregado via HuggingFace Datasets. Em seguida:

convertem-se os rótulos para valores numéricos (OBJ → 0, SUBJ → 1);

reduz-se o conjunto de colunas para apenas aquelas essenciais (sentence, labels, label);

remove-se, no caso de test\_unlabeled, qualquer coluna além de sentence.

A tokenização é realizada com o modelo RoBERTa-base, adotando truncamento e preenchimento até 256 tokens. Cada divisão dos dados passa a ser armazenada no formato PyTorch, possibilitando entrada direta no Trainer.

\subsubsection{Modelo}

Para a classificação, utilizamos AutoModelForSequenceClassification, inicializado a partir de roberta-base, com duas classes de saída. Essa arquitetura é adequada para capturar nuances semânticas em sentenças curtas, o que é fundamental na distinção entre subjetividade e objetividade.

\subsubsection{Estratégia de Treinamento}

O treinamento emprega:

30 épocas

learning rate = 2e-5

batch-size de 16 para treino e 32 para validação

weight decay de 0.01

A métrica principal utilizada foi F1-macro, complementada por accuracy.
A função compute\_metrics calcula ambos, utilizando o pacote evaluate.

Ao final do treinamento, o modelo é avaliado nos três conjuntos rotulados disponíveis: validation, dev\_test e test\_labeled.

\subsubsection{Resultados e Análise}

A curva de perda durante o treino foi registrada a partir do histórico do Trainer, permitindo avaliar o comportamento do modelo ao longo dos passos de otimização. A perda tende a diminuir de forma consistente, sugerindo convergência estável.

Para inferência, implementou-se a função classify\_subjectivity(), capaz de processar textos isolados ou em lote, retornando:

rótulo previsto: OBJ ou SUBJ

probabilidade estimada para a classe subjetiva

Por fim, o modelo treinado e o tokenizer foram salvos no Google Drive, garantindo reprodutibilidade e reutilização futura no ambiente de produção.

\section{Task 2 – Identificação de Causa de Emoção em Diálogos (SemEval-2024 ECAC)}

A segunda parte do projeto trata da tarefa de Extração de Causa de Emoção, cujo objetivo é identificar o trecho de texto que desencadeia uma emoção expressa em determinado turno de diálogo.

\subsection{Conversão para Formato de QA}

O dataset do SemEval-ECAC disponibiliza diálogos compostos por múltiplas falas e acompanhados de pares emoção – causa. Contudo, o modelo-base utilizado (RoBERTa-base para QA) exige o formato típico de Pergunta e Resposta (Question Answering).

Assim, cada diálogo é transformado em um exemplo QA com:

contexto: o diálogo completo, reconstruído linha a linha;

pergunta: “What is the cause of the emotion X?”;

resposta: o trecho textual correspondente ao cause span, acompanhado de seu índice de início no contexto.

Esse processo é realizado pela função conversation\_to\_qa\_examples(). Casos em que o span exato não é encontrado no contexto são descartados, seguindo estratégia adotada em competições anteriores.

\subsection{Tokenização e Alinhamento de Spans}

Como o QA exige alinhamento entre caracteres e tokens, foi implementada a função prepare\_train\_features(), que:

Tokeniza pares (pergunta, contexto);

Gera overflows com doc stride para lidar com contextos longos;

Mapeia cada resposta verdadeira para índices start\_positions e end\_positions;

Remove informações auxiliares desnecessárias para o treinamento.

Esse processo é central para garantir que o modelo consiga aprender localizações tokenizadas da causa emocional.

\subsection{Modelo e Treinamento}

O modelo empregado é o AutoModelForQuestionAnswering baseado em RoBERTa-base. O treinamento utiliza:

3 épocas

batch-size 8/16

learning rate = 3e-5

A métrica padrão do Trainer foi utilizada, embora avaliações mais avançadas (como EM/F1 no estilo SQuAD) possam ser integradas futuramente.

\subsubsection{Predição de Causas}

A função predict\_cause() recebe um contexto e o nome de uma emoção, constrói a pergunta correspondente e retorna o trecho estimado pelo modelo como causa. O processo envolve:

gerar logits de início e fim da resposta;

selecionar índices de maior probabilidade;

reconstruir a resposta a partir dos tokens decodificados.

Essa função é útil para testar casos individuais e para integrar a etapa de QA em aplicações reais.

\section{Limitações}

Apesar dos resultados promissores, este trabalho apresenta limitações que devem ser reconhecidas para uma interpretação adequada dos achados e para orientar pesquisas futuras. Primeiramente, a cobertura linguística e cultural das bases utilizadas pode introduzir vieses. Tanto corpora de detecção de subjetividade quanto bases de análise de causa de emoções frequentemente refletem padrões discursivos específicos de determinado país, período histórico ou linha editorial. Assim, os modelos podem capturar vieses implícitos presentes nas bases — por exemplo, associação desbalanceada entre determinados tópicos e polaridade emocional — comprometendo sua generalização para outros contextos jornalísticos.

Outra limitação diz respeito ao ruído intrínseco às anotações humanas. Em tarefas como subjetividade, emoção e causa de emoção, há um componente interpretativo inevitável. Anotadores podem divergir não apenas na identificação da emoção predominante, mas também sobre quais segmentos textuais constituem a causa. Isso afeta diretamente o desempenho dos modelos supervisionados, que aprendem padrões possivelmente inconsistentes. Além disso, nossas combinações de tarefas dependem fortemente da qualidade da segmentação e do mapeamento entre sentenças subjetivas e eventos causais, o que pode introduzir erros em cascata.

No plano computacional, o uso de modelos pré-treinados de linguagem pode gerar alucinações semânticas, especialmente em textos jornalísticos ambíguos ou com múltiplas interpretações possíveis. Embora tenhamos utilizado estratégias de fine-tuning e validação rigorosa, modelos grandes podem inferir relações causais inexistentes ou exagerar a subjetividade percebida, comprometendo a confiabilidade do sistema em aplicações reais.

\section{Considerações Éticas}

A aplicação de métodos automatizados para análise de subjetividade e emoção em notícias levanta preocupações éticas significativas. O uso desses sistemas por organizações públicas ou privadas pode influenciar decisões sensíveis, como monitoramento de mídia, avaliação de viés editorial ou análise de sentimentos sociais em larga escala. Sem uma supervisão adequada, o sistema pode reforçar preconceitos ou produzir interpretações enviesadas, impactando negativamente grupos sociais ou veículos jornalísticos.

Outro ponto crítico envolve o risco de uso indevido. Ferramentas capazes de identificar emoções e suas causas podem, em mãos inadequadas, ser aplicadas para manipulação discursiva, segmentação psicográfica ou vigilância de jornalistas e cidadãos. Assim, ressaltamos a necessidade de transparência metodológica, auditorias contínuas e diretrizes claras para limitar o uso dessas tecnologias a cenários eticamente apropriados.

Por fim, enfatizamos que o modelo não deve ser utilizado como substituto de análise humana qualificada. A interpretação de subjetividade e causalidade emocional em notícias é uma tarefa contextual e complexa; sistemas automáticos devem servir como apoio analítico, e não como autoridade decisória. Incentivamos que futuros trabalhos incluam auditorias de viés, testes em múltiplas culturas e mecanismos de interpretabilidade para fortalecer a responsabilidade no desenvolvimento e uso desses sistemas.

\section{Conclusão}

Ao propor a integração entre detecção de subjetividade e extração de causas de emoção, este trabalho buscou aproximar duas tarefas que, embora relacionadas do ponto de vista linguístico e pragmático, têm sido tratadas de maneira isolada na pesquisa em PLN. Nossos experimentos mostraram que a subjetividade é, de fato, um terreno fértil para a manifestação de conteúdo emocional, mas essa relação não é suficientemente forte para orientar de maneira consistente a extração de causas emocionais.

A ausência de ganhos sistemáticos no desempenho da ECE ao aplicar a filtragem por subjetividade evidencia uma limitação estrutural desse tipo de abordagem: causas emocionais não emergem apenas de trechos subjetivos, mas de construções discursivas mais amplas que incluem progressão temática, relações inferenciais e dependências entre turnos. Assim, embora o pipeline proposto seja conceitualmente coerente e empiricamente explorável, ele revela os limites de se tratar fenômenos afetivos e pragmáticos como etapas sequenciais e independentes.

Ainda assim, os resultados obtidos são valiosos para a compreensão do fenômeno. Eles sugerem que a integração entre tarefas pragmáticas não deve ser descartada, mas repensada sob modelos que articulem subjetividade, emoção e causalidade de forma mais profunda. Abordagens multitarefa, representações discursivas hierárquicas e mecanismos de interpretabilidade surgem como caminhos promissores para superar as limitações identificadas.

Em síntese, concluímos que a subjetividade é um indicador útil, porém insuficiente, e que avanços na extração de causas emocionais dependerão de modelos capazes de integrar múltiplos níveis de informação linguística. Esperamos que esta investigação incentive novas pesquisas que combinem linguística, modelagem neural e responsabilidade ética na análise automática de fenômenos subjetivos e emocionais.


\begin{thebibliography}{}

\bibitem[Arias et~al. 2022]{arias2022subjectivityMTL}
Arias, V., Silva, D., and Monteiro, A. 2022.
\newblock Subjectivity-Aware Multi-Task Learning for Sentiment and Emotion Analysis.
\newblock In \textit{Future Internet}.

\bibitem[Bhat and Modi 2022]{bhat2022mutec}
Bhat, A. and Modi, A. 2022.
\newblock MuTEC: A Multi-Task Framework for Emotion Causality in Conversations.
\newblock In \textit{Proceedings of PMLR}.

\bibitem[CheckThat! 2024]{checkthat2024overview}
CheckThat! Lab. 2024.
\newblock Overview of the CheckThat! 2024 Tasks.
\newblock In \textit{CLEF Working Notes}.

\bibitem[Gui et~al. 2017]{gui2017question}
Gui, L., Hu, J., He, Y., Xu, R., Lu, Q., and Du, J. 2017.
\newblock A Question Answering Approach for Emotion Cause Extraction.
\newblock In \textit{EMNLP}.

\bibitem[Neviarouskaya and Aono 2013]{neviarouskaya2013extracting}
Neviarouskaya, A. and Aono, M. 2013.
\newblock Extracting Causes of Emotions from Text.
\newblock In \textit{IJCNLP}.

\bibitem[Nguyen and Nguyen 2023]{nguyen2023guidedqa}
Nguyen, H.-H. and Nguyen, M.-T. 2023.
\newblock Emotion–Cause Pair Extraction as Guided Question Answering.
\newblock In \textit{ICAART}.

\bibitem[Poria et~al. 2021]{poria2021reccon}
Poria, S., etc. 2021.
\newblock RECCON: Emotion Causality in Conversations.
\newblock In \textit{ACL}.

\bibitem[Qiu et~al. 2022]{qiu2022survey}
Qiu, X., et al. 2022.
\newblock Survey on Automatic Emotion Cause Extraction from Texts.
\newblock \textit{Journal of Computer Research and Development}.

\bibitem[Sun et~al. 2021]{sun2021dqan}
Sun, Q., Yin, Y., and Yu, H. 2021.
\newblock Dual-Questioning Attention Networks for Emotion-Cause Pair Extraction.
\newblock In \textit{arXiv preprint}.

\bibitem[Tay et~al. 2019]{tay2019rthn}
Tay, Y., et al. 2019.
\newblock RTHN: A RNN–Transformer Hierarchical Network for ECE.
\newblock In \textit{ACL}.

\bibitem[Wiebe et~al. 2005]{wiebe2005annotating}
Wiebe, J., Wilson, T., and Cardie, C. 2005.
\newblock Annotating Expressions of Opinions and Emotions in Language.
\newblock \textit{Language Resources and Evaluation}.

\bibitem[Xia and Ding 2019]{xia2019ecpe}
Xia, R. and Ding, Z. 2019.
\newblock Emotion–Cause Pair Extraction: A New Task for Emotion Analysis.
\newblock In \textit{ACL}.

\bibitem[Yan et~al. 2021]{yan2021positionbias}
Yan, H., Gui, L., Pergola, G., and He, Y. 2021.
\newblock Position Bias Mitigation for Emotion Cause Extraction.
\newblock In \textit{arXiv preprint}.

\end{thebibliography}

\end{document}
