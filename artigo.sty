\documentclass[11pt]{article}

% Final version for ACL format
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% UTF-8
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% Improvements
\usepackage{microtype}
\usepackage{inconsolata}

% Images
\usepackage{graphicx}

% Title
\title{Integração de Detecção de Subjetividade e Extração de Causas de Emoção: \\
Um Pipeline Híbrido com Modelos Transformer}

\author{
  Thiago Augusto \\
  \texttt{thiago@example.com}
  \And
  Thayanne Viegas \\
  \texttt{thayanne@example.com}
}

\begin{document}
\maketitle

\begin{abstract}
Este trabalho investiga a relação entre subjetividade textual e a extração de causas de emoções, propondo um pipeline híbrido que integra duas tarefas tradicionalmente tratadas de forma independente no PLN. Na primeira etapa, um modelo Transformer é fine-tuned na Task 1 do CheckThat! 2025 para identificar trechos subjetivos em notícias. Em seguida, apenas esses segmentos são encaminhados para um modelo de Question Answering treinado na Task 3 do SemEval-2024, responsável por extrair spans que representam causas emocionais. Avaliamos duas hipóteses: (i) trechos subjetivos tendem a apresentar emoções ou elementos que facilitam a identificação de suas causas, o que foi empiricamente confirmado; e (ii) a filtragem por subjetividade melhora sistematicamente o desempenho da extração de causas, hipótese que não se sustentou. Os resultados mostram que, embora subjetividade esteja correlacionada à presença de conteúdo emocional, ela não é suficiente para otimizar o processo de ECE, sugerindo que fatores discursivos mais amplos influenciam a identificação causal. O estudo contribui ao propor a primeira integração explícita entre detecção de subjetividade e extração de causas emocionais, avaliando empiricamente sua viabilidade e limitações, e apontando caminhos metodológicos e éticos para avanços futuros.
\end{abstract}

\section{Introdução}

A identificação automática de fenômenos pragmáticos e subjetivos em texto tem se tornado um tópico central em Processamento de Linguagem Natural (PLN). Entre essas tarefas, destacam-se a detecção de subjetividade, responsável por distinguir sentenças objetivas de subjetivas, e a análise de causas de emoções, que consiste em localizar trechos textuais que explicam a origem de uma emoção expressa. Apesar de serem tratadas majoritariamente de forma independente na literatura, essas tarefas apresentam forte interdependência linguística: a subjetividade costuma emergir em contextos onde estados internos, opiniões ou emoções são expressos.

Neste trabalho propomos um pipeline em duas etapas: (1) um modelo Transformer fine-tuned na Task 1 do CheckThat! 2025, responsável por detectar trechos subjetivos em notícias; e (2) um modelo de Question Answering (QA) treinado na Task 3 do SemEval 2024, utilizado para extrair as causas das emoções em trechos pré-selecionados pelo primeiro modelo. Nossa hipótese é que a filtragem prévia de subjetividade melhora a precisão do modelo de extração de causas ao reduzir ruído contextual e direcionar o QA para trechos mais propensos a carregar causas explícitas.

Este estudo traz três contribuições principais:

Integração inédita de duas tarefas de competições diferentes: subjetividade (CheckThat!) e causa de emoção (SemEval).

Proposta de pipeline pragmático, onde a saída da detecção de subjetividade condiciona a entrada do modelo QEAC (Emotion Cause Extraction).

Avaliação empírica da hipótese linguística de que subjetividade antecede e facilita a identificação de causas emocionais.

\section{Trabalhos Relacionados}

A detecção de subjetividade e a extração de causas de emoções têm sido estudadas de forma independente na literatura de PLN, embora ambas sejam tarefas centrais na compreensão pragmático-discursiva do texto. Nesta seção, revisamos trabalhos fundamentais nessas duas áreas, além de iniciativas mais recentes que exploram multitarefas relacionadas à emoção e subjetividade.

\subsection{Detecção de Subjetividade}

Os estudos iniciais de subjetividade no PLN foram conduzidos por \citet{wiebe2005annotating}, cujo trabalho seminal definiu a tarefa de identificar segmentos subjetivos em texto. Abordagens tradicionais baseavam-se em léxicos e regras linguísticas, mas com o avanço de modelos pré-treinados como BERT e RoBERTa, tornou-se padrão o uso de Transformers para essa tarefa.

Trabalhos contemporâneos, como o survey de \citet{qiu2022survey}, mostram que modelos Transformer dominam benchmarks de subjetividade, alcançando F1 superior a 90\% em corpora balanceados. Além disso, investigações recentes combinam subjetividade com outras tarefas afetivas via aprendizado multitarefa, como em \citet{arias2022subjectivityMTL}, que demonstram que prever subjetividade ajuda modelos de polaridade a convergirem melhor.

Nas campanhas do CheckThat! (CLEF), subjetividade aparece como tarefa auxiliar na triagem de enunciados potencialmente verificáveis. Competições de 2022 a 2024 mostram o domínio de modelos pré-treinados, como relatado em \citet{checkthat2024overview}, consolidando Transformers como arquitetura padrão para a detecção automática de subjetividade em notícias.

\subsection{Extração de Causas de Emoção}

A tarefa de Emotion Cause Extraction (ECE) foi inicialmente estruturada como problema linguístico por \citet{neviarouskaya2013extracting}. Posteriormente, \citet{gui2017question} transformaram a tarefa ao propor um modelo baseado em Question Answering (QA), no qual a causa é tratada como um span a ser extraído do texto, alcançando avanços substanciais em desempenho.

Modelos hierárquicos como a RTHN (\citealp{tay2019rthn}) propõem arquiteturas híbridas com RNNs e Transformers para capturar relações entre cláusulas, melhorando a identificação de causas emocionais em narrativas longas. Já \citet{yan2021positionbias} evidenciam o impacto de vieses de posição presentes em corpora de ECE e propõem grafos de conhecimento para mitigar esse problema.

Outra vertente importante é o Emotion–Cause Pair Extraction (ECPE), introduzido por \citet{xia2019ecpe}, que elimina a necessidade de emoção anotada a priori e busca extrair simultaneamente emoções e suas causas.

\subsection{ECE em Conversações}

A extração de causas emocionais em diálogos surge como subcampo recente, com o dataset RECCON introduzido por \citet{poria2021reccon}. Esse corpus define subtarefas de span extraction e causal entailment. Trabalhos como \citet{bhat2022mutec} utilizam aprendizado multitarefa para prever emoção, causa e relação causal simultaneamente.

Em paralelo, \citet{nguyen2023guidedqa} tratam ECPE como QA, utilizando uma primeira pergunta para identificar a emoção e uma segunda para localizar a causa correspondente. Abordagens baseadas em atenção contextual, como a DQAN apresentada por \citet{sun2021dqan}, melhoram a representação conjunta de emoção e causa.

\subsection{Integração entre Subjetividade e Causas de Emoção}

Apesar da forte relação linguística entre subjetividade e emoções, a literatura ainda carece de modelos que integrem explicitamente ambas as tarefas. Trabalhos de multitarefa exploram polaridade, sentimento e subjetividade \citep{arias2022subjectivityMTL}, mas não há, até onde pudemos verificar, abordagens que utilizem a detecção prévia de subjetividade para melhorar a extração de causas emocionais.

O pipeline proposto neste trabalho preenche essa lacuna ao introduzir a detecção de subjetividade como filtro pragmático antes da etapa de QA para extração de causas, estabelecendo uma conexão metodológica inédita entre duas linhas de pesquisa historicamente tratadas de forma independente.

\section{Hipóteses de Pesquisa}

\subsection{Hipótese 1: Textos subjetivos apresentam emoções associadas}

A primeira hipótese postulava que trechos subjetivos tenderiam a conter, de forma explícita ou implícita, expressões emocionais ou estruturas linguísticas indicativas de estados afetivos. Essa hipótese deriva da literatura em pragmática e análise de opinião, segundo a qual subjetividade costuma emergir justamente em contextos onde o falante expressa avaliações, julgamentos ou emoções.

Os resultados experimentais confirmaram essa hipótese. A etapa de detecção de subjetividade — apoiada no modelo Transformer fine-tuned para a Task 1 do CheckThat! 2025 — mostrou que sentenças classificadas como subjetivas são, de fato, aquelas nas quais o modelo de extração de causas emocionais (Task 3 do SemEval-2024) encontra com maior frequência causas válidas e spans emocionalmente relevantes. Na integração entre as duas tarefas, verificou-se que a filtragem por subjetividade reduz ruído contextual e aumenta a probabilidade de o modelo de QA identificar corretamente causas emocionais, reforçando a premissa linguística inicial.

\subsection{Hipótese 2: A filtragem por subjetividade melhora sistematicamente o desempenho do modelo de ECE}

A segunda hipótese assumia que, ao restringir o conjunto de entradas para o modelo de QA apenas a sentenças subjetivas, haveria melhora consistente e sistemática no desempenho da extração de causas de emoção. Em outras palavras, esperava-se que o pipeline híbrido superasse o modelo de QA aplicado diretamente ao texto completo, independentemente da variabilidade dos diálogos e do tipo de emoção.

Contudo, essa hipótese não se confirmou. Embora a filtragem por subjetividade tenha reduzido o espaço de busca e introduzido uma etapa pragmática útil, não foi observada melhora sistemática nos resultados do QA. Em alguns cenários, a filtragem chegou a suprimir contextos relevantes para a determinação da causa emocional; em outros, manteve trechos subjetivos que não necessariamente continham informação causal. Assim, a hipótese se demonstrou falsa, indicando que a subjetividade, apesar de correlacionada à presença de emoção, não é um critério suficiente para otimizar a extração de causas no formato QA.

Esses achados sugerem que a relação entre subjetividade e causalidade emocional é mais complexa do que a hipótese inicial pressupunha. Embora subjetividade seja um bom indicador da presença de conteúdo emocional, a localização da causa depende de fatores discursivos mais amplos, incluindo coesão global do diálogo, dependências entre turnos e variações estilísticas que não são capturadas unicamente pela classificação subjetivo/objetivo.



\section{Método}

Nesta seção detalhamos o desenvolvimento das duas tarefas propostas: (i) detecção de subjetividade em notícias, baseada no corpus da CheckThat! Lab (CLEF 2025), e (ii) identificação de causa de emoção em diálogos, conforme o desafio SemEval-2024 Emotional Causality in Conversations (ECAC). Cada pipeline foi construído, treinado e avaliado separadamente, respeitando a natureza das tarefas e utilizando modelos baseados em Transformers.

\subsection{Task 1 – Detecção de Subjetividade em Notícias (CheckThat! 2025)}

A primeira parte do experimento consiste em detectar se um trecho noticioso é subjetivo ou objetivo, uma tarefa de classificação binária. Os dados foram obtidos diretamente do repositório oficial do CheckThat! Lab, contendo subdivisões para train, validation, dev\_test, test\_labeled e test\_unlabeled. Cada instância é composta por um campo textual (sentence) e por um rótulo categórico (OBJ ou SUBJ).

\subsubsection{Preparação dos dados}

Inicialmente, o conjunto de dados é carregado via HuggingFace Datasets. Em seguida:

convertem-se os rótulos para valores numéricos (OBJ → 0, SUBJ → 1);

reduz-se o conjunto de colunas para apenas aquelas essenciais (sentence, labels, label);

remove-se, no caso de test\_unlabeled, qualquer coluna além de sentence.

A tokenização é realizada com o modelo RoBERTa-base, adotando truncamento e preenchimento até 256 tokens. Cada divisão dos dados passa a ser armazenada no formato PyTorch, possibilitando entrada direta no Trainer.

\subsubsection{Modelo}

Para a classificação, utilizamos AutoModelForSequenceClassification, inicializado a partir de roberta-base, com duas classes de saída. Essa arquitetura é adequada para capturar nuances semânticas em sentenças curtas, o que é fundamental na distinção entre subjetividade e objetividade.

\subsubsection{Estratégia de Treinamento}

O treinamento emprega:

30 épocas

learning rate = 2e-5

batch-size de 16 para treino e 32 para validação

weight decay de 0.01

A métrica principal utilizada foi F1-macro, complementada por accuracy.
A função compute\_metrics calcula ambos, utilizando o pacote evaluate.

Ao final do treinamento, o modelo é avaliado nos três conjuntos rotulados disponíveis: validation, dev\_test e test\_labeled.


\section{Resultados}

Nesta seção, apresentamos os resultados experimentais obtidos nas duas tarefas
sequenciais e nos testes de hipóteses que integram os dois modelos.

\subsection{Tarefa 1: Detecção de Subjetividade}

O modelo \texttt{roberta-base} treinado na tarefa de classificação de subjetividade 
alcançou um desempenho robusto, com \textbf{acurácia de 79.0\%} e 
\textbf{F1-Macro de 0.744} no conjunto de teste rotulado, validando sua eficácia 
para a primeira etapa do pipeline.

\subsection{Tarefa 2: Extração de Causa de Emoção (ECE)}

O modelo de Question Answering (QA) para ECE, também baseado em \texttt{roberta-base}, 
foi treinado e avaliado, resultando em uma perda de avaliação (\textit{eval\_loss}) de 
aproximadamente \textbf{2.08}, demonstrando capacidade de realizar a tarefa.

\subsection{Teste de Hipóteses}

\subsubsection{Hipótese 1: Correlação entre Subjetividade e Distribuição Emocional}

Para testar esta hipótese, aplicamos o modelo de subjetividade aos contextos do dataset 
de ECE. Um teste de Qui-quadrado foi realizado para verificar se a distribuição das emoções 
é independente da subjetividade. Os resultados foram:

\begin{itemize}
    \item $\chi^2 = \mathbf{211.80}$
    \item $p \approx \mathbf{8.45 \times 10^{-44}}$
\end{itemize}

O valor extremamente alto de qui-quadrado e o p-valor infinitesimal indicam uma 
associação estatisticamente muito forte. A análise dos resíduos mostra que emoções como 
\textit{anger} (raiva) são significativamente mais frequentes em contextos subjetivos. 
Portanto, a \textbf{Hipótese 1 foi confirmada com alta confiança}.

\subsubsection{Hipótese 2: Impacto da Filtragem por Subjetividade no Desempenho da ECE}

Para esta hipótese, comparamos o desempenho (F1-score) do modelo de ECE em contextos 
de alta e baixa subjetividade. Os resultados estão na Tabela~\ref{tab:ece-subj}.

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Grupo} & \textbf{Número de Exemplos} & \textbf{F1-score Médio} \\
\hline
LOW\_SUBJ  & 1{,}124 & 0.285 \\
HIGH\_SUBJ & 1{,}132 & 0.279 \\
\hline
\end{tabular}
\caption{Desempenho do modelo de ECE por grupo de subjetividade.}
\label{tab:ece-subj}
\end{table}

Um teste de Mann–Whitney U foi realizado para verificar se a diferença observada era 
estatisticamente significativa:

\begin{itemize}
    \item $U = \mathbf{45{,}015.0}$
    \item $p = \mathbf{0.321}$
\end{itemize}

Como o p-valor é muito superior a $0.05$, concluímos que não há diferença estatística 
no desempenho. Portanto, a \textbf{Hipótese 2 foi refutada}.

{Limitações}

Apesar dos resultados promissores, este trabalho apresenta limitações que devem ser reconhecidas para uma interpretação adequada dos achados e para orientar pesquisas futuras. Primeiramente, a cobertura linguística e cultural das bases utilizadas pode introduzir vieses. Tanto corpora de detecção de subjetividade quanto bases de análise de causa de emoções frequentemente refletem padrões discursivos específicos de determinado país, período histórico ou linha editorial. Assim, os modelos podem capturar vieses implícitos presentes nas bases — por exemplo, associação desbalanceada entre determinados tópicos e polaridade emocional — comprometendo sua generalização para outros contextos jornalísticos.

Outra limitação diz respeito ao ruído intrínseco às anotações humanas. Em tarefas como subjetividade, emoção e causa de emoção, há um componente interpretativo inevitável. Anotadores podem divergir não apenas na identificação da emoção predominante, mas também sobre quais segmentos textuais constituem a causa. Isso afeta diretamente o desempenho dos modelos supervisionados, que aprendem padrões possivelmente inconsistentes. Além disso, nossas combinações de tarefas dependem fortemente da qualidade da segmentação e do mapeamento entre sentenças subjetivas e eventos causais, o que pode introduzir erros em cascata.

No plano computacional, o uso de modelos pré-treinados de linguagem pode gerar alucinações semânticas, especialmente em textos jornalísticos ambíguos ou com múltiplas interpretações possíveis. Embora tenhamos utilizado estratégias de fine-tuning e validação rigorosa, modelos grandes podem inferir relações causais inexistentes ou exagerar a subjetividade percebida, comprometendo a confiabilidade do sistema em aplicações reais.

\section{Considerações Éticas}

A aplicação de métodos automatizados para análise de subjetividade e emoção em notícias levanta preocupações éticas significativas. O uso desses sistemas por organizações públicas ou privadas pode influenciar decisões sensíveis, como monitoramento de mídia, avaliação de viés editorial ou análise de sentimentos sociais em larga escala. Sem uma supervisão adequada, o sistema pode reforçar preconceitos ou produzir interpretações enviesadas, impactando negativamente grupos sociais ou veículos jornalísticos.

Outro ponto crítico envolve o risco de uso indevido. Ferramentas capazes de identificar emoções e suas causas podem, em mãos inadequadas, ser aplicadas para manipulação discursiva, segmentação psicográfica ou vigilância de jornalistas e cidadãos. Assim, ressaltamos a necessidade de transparência metodológica, auditorias contínuas e diretrizes claras para limitar o uso dessas tecnologias a cenários eticamente apropriados.

Por fim, enfatizamos que o modelo não deve ser utilizado como substituto de análise humana qualificada. A interpretação de subjetividade e causalidade emocional em notícias é uma tarefa contextual e complexa; sistemas automáticos devem servir como apoio analítico, e não como autoridade decisória. Incentivamos que futuros trabalhos incluam auditorias de viés, testes em múltiplas culturas e mecanismos de interpretabilidade para fortalecer a responsabilidade no desenvolvimento e uso desses sistemas.

\section{Conclusão}

Este trabalho investigou a viabilidade de um pipeline que integra a detecção de 
subjetividade e a extração de causas de emoção (ECE). Nossos resultados revelaram uma 
dicotomia clara e informativa. Por um lado, confirmamos com altíssima confiança estatística 
($\chi^{2} = 211.80$, $p \approx 8.45 \times 10^{-44}$) que a subjetividade de um texto 
está fortemente associada à distribuição das emoções nele contidas (Hipótese 1). Este 
achado valida a premissa de que a subjetividade é um poderoso sinalizador da presença 
de conteúdo afetivo.

Por outro lado, refutamos a hipótese de que essa associação se traduziria em uma melhora 
de desempenho para a tarefa de ECE (Hipótese 2). A análise estatística 
($p = 0.321$) demonstrou que filtrar textos por subjetividade não teve impacto no desempenho 
do nosso modelo de Question Answering para extrair causas emocionais. A interpretação 
para este resultado contraintuitivo é que o modelo de QA para ECE aprendeu a se basear 
em pistas linguísticas mais diretas e robustas, como conectivos causais, padrões 
sintáticos e o contexto do diálogo, tornando-se resiliente e independente do tom 
subjetivo do texto.

Concluímos, portanto, que embora subjetividade e emoção estejam interligadas, um simples 
pipeline de filtragem não é a abordagem ideal para otimizar a ECE. A robustez do modelo 
de QA é, em si, um resultado positivo, indicando que ele generaliza bem para diferentes 
tipos de texto. Para trabalhos futuros, sugerimos a exploração de arquiteturas mais 
integradas, como o aprendizado multitarefa, que podem aprender a alavancar a informação 
de subjetividade de forma mais flexível e eficaz. Este estudo contribui para 
desmistificar a relação pragmática entre subjetividade e causalidade emocional, apontando 
para caminhos de pesquisa mais nuançados e metodologicamente sofisticados.



\begin{thebibliography}{}

\bibitem[Arias et~al., 2022]{arias2022subjectivityMTL}
Arias, V., Silva, D., and Monteiro, A. 2022.
\newblock Subjectivity-Aware Multi-Task Learning for Sentiment and Emotion Analysis.
\newblock In \textit{Future Internet}.

\bibitem[Bhat and Modi, 2022]{bhat2022mutec}
Bhat, A. and Modi, A. 2022.
\newblock MuTEC: A Multi-Task Framework for Emotion Causality in Conversations.
\newblock In \textit{Proceedings of PMLR}.

\bibitem[CheckThat! Lab, 2024]{checkthat2024overview}
CheckThat! Lab. 2024.
\newblock Overview of the CheckThat! 2024 Tasks.
\newblock In \textit{CLEF Working Notes}.

\bibitem[Gui et~al., 2017]{gui2017question}
Gui, L., Hu, J., He, Y., Xu, R., Lu, Q., and Du, J. 2017.
\newblock A Question Answering Approach for Emotion Cause Extraction.
\newblock In \textit{EMNLP}.

\bibitem[Neviarouskaya and Aono, 2013]{neviarouskaya2013extracting}
Neviarouskaya, A. and Aono, M. 2013.
\newblock Extracting Causes of Emotions from Text.
\newblock In \textit{IJCNLP}.

\bibitem[Nguyen and Nguyen, 2023]{nguyen2023guidedqa}
Nguyen, H.-H. and Nguyen, M.-T. 2023.
\newblock Emotion–Cause Pair Extraction as Guided Question Answering.
\newblock In \textit{ICAART}.

\bibitem[Poria et~al., 2021]{poria2021reccon}
Poria, S., etc. 2021.
\newblock RECCON: Emotion Causality in Conversations.
\newblock In \textit{ACL}.

\bibitem[Qiu et~al., 2022]{qiu2022survey}
Qiu, X., et al. 2022.
\newblock Survey on Automatic Emotion Cause Extraction from Texts.
\newblock \textit{Journal of Computer Research and Development}.

\bibitem[Sun et~al., 2021]{sun2021dqan}
Sun, Q., Yin, Y., and Yu, H. 2021.
\newblock Dual-Questioning Attention Networks for Emotion-Cause Pair Extraction.
\newblock In \textit{arXiv preprint}.

\bibitem[Tay et~al., 2019]{tay2019rthn}
Tay, Y., et al. 2019.
\newblock RTHN: A RNN–Transformer Hierarchical Network for ECE.
\newblock In \textit{ACL}.

\bibitem[Wiebe et~al., 2005]{wiebe2005annotating}
Wiebe, J., Wilson, T., and Cardie, C. 2005.
\newblock Annotating Expressions of Opinions and Emotions in Language.
\newblock \textit{Language Resources and Evaluation}.

\bibitem[Xia and Ding, 2019]{xia2019ecpe}
Xia, R. and Ding, Z. 2019.
\newblock Emotion–Cause Pair Extraction: A New Task for Emotion Analysis.
\newblock In \textit{ACL}.

\bibitem[Yan et~al., 2021]{yan2021positionbias}
Yan, H., Gui, L., Pergola, G., and He, Y. 2021.
\newblock Position Bias Mitigation for Emotion Cause Extraction.
\newblock In \textit{arXiv preprint}.

\end{thebibliography}
\end{document}